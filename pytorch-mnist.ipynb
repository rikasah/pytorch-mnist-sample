{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9912320/9912422 [02:42<00:00, 41620.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:07<?, ?it/s]\u001b[A\n",
      "9920512it [03:00, 41620.36it/s]                             \n",
      " 57%|█████▋    | 16384/28881 [00:17<00:07, 1571.97it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8192/1648877 [00:06<07:40, 3563.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:07<06:04, 4484.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 24576/1648877 [00:07<04:32, 5955.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 32768/1648877 [00:08<04:24, 6104.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 40960/1648877 [00:09<04:07, 6507.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 65536/1648877 [00:10<03:03, 8622.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 73728/1648877 [00:10<02:15, 11663.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 90112/1648877 [00:11<01:55, 13528.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 106496/1648877 [00:11<01:23, 18398.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 122880/1648877 [00:11<01:01, 24685.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 131072/1648877 [00:12<01:42, 14839.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 147456/1648877 [00:12<01:19, 18968.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 163840/1648877 [00:13<01:02, 23867.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 180224/1648877 [00:13<00:46, 31496.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 188416/1648877 [00:13<01:02, 23381.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 196608/1648877 [00:14<01:01, 23602.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 212992/1648877 [00:14<00:47, 30078.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 229376/1648877 [00:14<00:36, 38906.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 245760/1648877 [00:14<00:28, 49933.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 262144/1648877 [00:15<00:39, 35217.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 278528/1648877 [00:15<00:40, 33837.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 286720/1648877 [00:16<00:34, 39289.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 294912/1648877 [00:17<01:34, 14300.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 434176/1648877 [00:17<01:00, 20000.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 450560/1648877 [00:18<00:45, 26094.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 466944/1648877 [00:18<00:36, 32718.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 483328/1648877 [00:18<00:27, 42251.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 499712/1648877 [00:18<00:21, 53424.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 516096/1648877 [00:18<00:17, 65399.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 540672/1648877 [00:18<00:13, 79879.11it/s]\u001b[A\u001b[A\n",
      "32768it [00:36, 1571.97it/s]                           \u001b[A\n",
      "\n",
      " 34%|███▍      | 557056/1648877 [00:19<00:12, 84052.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 573440/1648877 [00:21<01:02, 17193.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 589824/1648877 [00:22<00:48, 21815.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 630784/1648877 [00:22<00:34, 29864.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 647168/1648877 [00:23<00:38, 26018.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 827392/1648877 [00:26<00:26, 30518.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 843776/1648877 [00:26<00:20, 39790.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 860160/1648877 [00:26<00:15, 49519.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 876544/1648877 [00:27<00:13, 57002.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 892928/1648877 [00:27<00:15, 49583.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 950272/1648877 [00:27<00:10, 67738.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 974848/1648877 [00:27<00:07, 85957.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 999424/1648877 [00:27<00:06, 103627.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 1081344/1648877 [00:27<00:04, 139840.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 1146880/1648877 [00:28<00:02, 181766.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 1196032/1648877 [00:28<00:02, 211398.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 1245184/1648877 [00:28<00:01, 250021.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 1294336/1648877 [00:28<00:02, 152741.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1449984/1648877 [00:28<00:00, 209356.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 1523712/1648877 [00:29<00:00, 232688.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 1589248/1648877 [00:29<00:00, 271015.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1646592/1648877 [00:29<00:00, 267870.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "8192it [00:00, 14624.34it/s]            \u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1654784it [00:48, 267870.32it/s]                             \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 64 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "## Then define the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.1\n",
    "momentum = 0.00003\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) #using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79436250f7954b8ba51eb561bbf2e893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0784, Accuracy: 9761/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff6d53ac824e969465426934a379e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0790, Accuracy: 9765/10000 (98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f23ff624ad0457082b17b8d1e21d461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=938), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0792, Accuracy: 9753/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 3\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
      "         Dropout2d-3             [-1, 20, 8, 8]               0\n",
      "            Linear-4                   [-1, 50]          16,050\n",
      "            Linear-5                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.15\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
